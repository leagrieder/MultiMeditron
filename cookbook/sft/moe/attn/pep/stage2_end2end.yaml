base_llm: meta-llama/Llama-3.1-8B-Instruct
base_model: $MODEL_ROOT/freeze/attn_pep/MultiMeditron-8B-attn-pep-alignment/checkpoint-666 # path to the alignment checkpoint
resume_from_checkpoint: false
wandb_run_id: null
attachment_token: <|reserved_special_token_0|>
tokenizer_type: llama
token_size: 4096
truncation: true
max_sequence_length: 4096

loaders:
  - loader_type: raw-image
    modality_type: image

modalities:
  - model_type: moe_meditron_clip_pep
    image_processor: openai/clip-vit-base-patch32
    hidden_size: 4096
    expert_clip_names:
      - ClosedMeditron/MedExpert-CT
      - ClosedMeditron/MedExpert-MRI
      - ClosedMeditron/MedExpert-Ultrasound
      - ClosedMeditron/MedExpert-Xray
      - ClosedMeditron/clip-vit-base-patch32
    generalist_idx : -1
    gating_path: ClosedMeditron/MultiMeditron-Gating
    fusion_method: cross_attn
    top_k_experts: 5

training_mode: END2END

datasets:
  - packed_path: $STORAGE_ROOT/BUSI
  - packed_path: $STORAGE_ROOT/COVID_US
  - packed_path: $STORAGE_ROOT/ct2
  - packed_path: $STORAGE_ROOT/iu_xray
  - packed_path: $STORAGE_ROOT/PMC_VQA_FULL
  - packed_path: $STORAGE_ROOT/llava_instruct
  - packed_path: $STORAGE_ROOT/medtrinity_conversations_1_formatted
  - packed_path: $STORAGE_ROOT/medtrinity_conversations_2_formatted
  - packed_path: $STORAGE_ROOT/image_mammoth

training_args:
  output_dir: $MODEL_ROOT/unfreeze/attn_pep/MultiMeditron-8B-attn-pep-end2end
  run_name: MultiMeditron-8B-attn-pep-end2end
  dataloader_num_workers: 16
  dataloader_prefetch_factor: 4
  remove_unused_columns: false
  ddp_find_unused_parameters: false
  learning_rate: 1.0e-5
  bf16: true
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  num_train_epochs: 1
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: true
  save_strategy: steps
  save_steps: 0.25
  max_grad_norm: 1.0
  deepspeed: $WORKING_DIR/config/deepspeed.json
  accelerator_config:
    dispatch_batches: false
  lr_scheduler_type: cosine_with_min_lr
  lr_scheduler_kwargs:
    min_lr: 1.0e-6
  report_to: wandb
  logging_steps: 1
  weight_decay: 0.01
