{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and label Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "# Function to extract and label images by modality\n",
    "def prepare_data(source_dir, target_dir, modalities):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for folder in dirs:\n",
    "            if folder in modalities:\n",
    "                modality_folder = os.path.join(root, folder)\n",
    "                target_modality_dir = os.path.join(target_dir, folder)\n",
    "                os.makedirs(target_modality_dir, exist_ok=True)\n",
    "\n",
    "                for file in os.listdir(modality_folder):\n",
    "                    folder_path = os.path.join(modality_folder, file)\n",
    "                    if os.path.isdir(folder_path):\n",
    "                        for image in os.listdir(folder_path):\n",
    "                            file_path = os.path.join(folder_path, image)\n",
    "                            target_path = os.path.join(target_modality_dir, file)\n",
    "                            shutil.copy(file_path, target_modality_dir)\n",
    "                            \n",
    "\n",
    "# Source and target directories\n",
    "#source_dir = '/mloscratch/homes/tagemoua/scrap_radiopaedia/radiopaedia'\n",
    "#target_dir = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data'\n",
    "#modalities = 'Ultrasound'\n",
    "\n",
    "# Prepare the dataset\n",
    "#prepare_data(source_dir, target_dir, modalities)\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# prepare data chexpert\n",
    "\n",
    "def prepare_data_chexpert(source_dir, target_dir, modality):\n",
    "    with open(source_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line_data = json.loads(line.strip())  # Remove whitespace and parse JSON\n",
    "            jsonl_image_path = line_data['modalities'][0]['value']\n",
    "            image_path = os.path.join('/mloscratch/homes/multimeditron/dataset/image/PMC-OA', jsonl_image_path)\n",
    "            #jsonl_image_path = jsonl_image_path.split('/')\n",
    "            \n",
    "            target_path = os.path.join(target_dir, modality)\n",
    "            # Extracting the study ID (assuming it's part of the image path or metadata)\n",
    "            #study_id = jsonl_image_path[-2] # Replace with actual field if needed\n",
    "            \n",
    "            # Create a target directory based on modality\n",
    "            target_path = os.path.join(target_dir, modality)\n",
    "            \n",
    "            # Get the base image filename and create a new filename\n",
    "            base_name = os.path.basename(image_path)\n",
    "            new_image_name = f\"{study_id}_{base_name}\"\n",
    "            new_image_path = os.path.join(target_path, new_image_name)\n",
    "            os.makedirs(target_path, exist_ok=True)\n",
    "            \n",
    "\n",
    "            print(f\"Copying {image_path} to {new_image_path}\")\n",
    "            try:\n",
    "                shutil.copy(image_path, new_image_path)\n",
    "                print(\"Image copied successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                if image_path.lower().endswith(('.png')):\n",
    "                    try:\n",
    "                        new_image_path = image_path.replace('.jjpg')\n",
    "                        shutil.copy(new_image_path, target_path)\n",
    "                        print(\"Image copied successfully\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "\n",
    "#source_dir = '/mloscratch/homes/multimeditron/dataset/image/PMC-OA.jsonl'\n",
    "\n",
    "#target_dir = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data'\n",
    "#modality = 'General Medecine'\n",
    "#prepare_data(source_dir, target_dir, modality)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to create a subset of image files\n",
    "\n",
    "def create_subset(input_dirs, output_dir, subset_size=100):\n",
    "    \"\"\"\n",
    "    Create a subset of image files from multiple directories.\n",
    "\n",
    "    :param input_dirs: List of input directories containing image files.\n",
    "    :param output_dir: Target directory to save the subset.\n",
    "    :param subset_size: Number of images to take from each input directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "    for input_dir in input_dirs:\n",
    "        if not os.path.exists(input_dir):\n",
    "            print(f\"Directory {input_dir} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # List all files in the current directory\n",
    "        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n",
    "        \n",
    "        # Limit to the subset size\n",
    "        subset_files = files[:subset_size]\n",
    "\n",
    "        # Create a subfolder in the output directory for this class (same name as input folder)\n",
    "        class_name = os.path.basename(input_dir)\n",
    "        class_output_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the subset files to the output directory\n",
    "        for file in subset_files:\n",
    "            src_path = os.path.join(input_dir, file)\n",
    "            dst_path = os.path.join(class_output_dir, file)\n",
    "            shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "        print(f\"Copied {len(subset_files)} files from {input_dir} to {class_output_dir}\")\n",
    "\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/runai-home/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 322MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1634, Accuracy: 94.80%\n",
      "Validation Loss: 0.0917, Accuracy: 97.51%\n",
      "Epoch [2/10], Loss: 0.0625, Accuracy: 98.06%\n",
      "Validation Loss: 0.0900, Accuracy: 97.23%\n",
      "Epoch [3/10], Loss: 0.0479, Accuracy: 98.48%\n",
      "Validation Loss: 0.1174, Accuracy: 96.36%\n",
      "Epoch [4/10], Loss: 0.0394, Accuracy: 98.77%\n",
      "Validation Loss: 0.0819, Accuracy: 97.30%\n",
      "Epoch [5/10], Loss: 0.0462, Accuracy: 98.64%\n",
      "Stopping early at epoch 5 due to no improvement in accuracy and an increase in loss.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "target_dir = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data'\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_data = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset'\n",
    "# Dataset preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root=new_data, transform=transform)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(data, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model preparation\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_classes = len(data.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model with early stopping based on loss and accuracy\n",
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "prev_loss = float('inf')  # Initialize with a high value\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy for this batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Compute epoch loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping condition\n",
    "    if epoch > 0 and epoch_loss > prev_loss and epoch_accuracy <= best_accuracy:\n",
    "        print(f\"Stopping early at epoch {epoch+1} due to no improvement in accuracy and an increase in loss.\")\n",
    "        break\n",
    "\n",
    "    # Update best accuracy and previous loss for comparison\n",
    "    best_accuracy = max(best_accuracy, epoch_accuracy)\n",
    "    prev_loss = epoch_loss\n",
    "\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'modality_classifier.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the expert to use for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "new_data = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500'\n",
    "# Dataset preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root=new_data, transform=transform)\n",
    "\n",
    "# Load the trained model\n",
    "model = models.resnet50(pretrained=False)  # Don't load pretrained weights, we'll load our own\n",
    "num_classes = len(data.classes)  # Number of classes in the dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust final layer to match the number of classes\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('modality_classifier_500.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Determine the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # Move the model to the correct device\n",
    "\n",
    "\n",
    "\n",
    "# Function to predict a class for a random image\n",
    "def predict_image(image_path):\n",
    "    # Open the image using OpenCV (or PIL if preferred)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert the image to RGB (OpenCV loads images in BGR by default)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to PIL format\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Apply transformations\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the image tensor to the same device as the model\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    predicted_class = data.classes[predicted.item()]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "\n",
    "# Test the model with a random image\n",
    "#image_path = '/mloscratch/homes/tagemoua/scrap_radiopaedia/radiopeadia/Ultrasound/abdominal-ectopic-pregnancy-in-the-second-trimester-1/images/0bb8915dd09a1254260d005cf4cae02d82e2d232453adbfefa956065a9cd973e_thumb.jpeg'\n",
    "#predict_image(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: General (Entropy: 0.0012)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.stats import entropy  # To calculate entropy\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "# Dataset directory and transformations\n",
    "new_data = '/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root=new_data, transform=transform)\n",
    "\n",
    "# Load the trained model\n",
    "model = models.resnet50(pretrained=False)  # Don't load pretrained weights\n",
    "num_classes = len(data.classes)  # Number of classes in the dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust the final layer\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('modality_classifier_3000.pth', map_location='cpu'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Determine the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # Move the model to the correct device\n",
    "\n",
    "# Define entropy threshold\n",
    "ENTROPY_THRESHOLD = 0.2\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    \"\"\"Calculate the entropy of a probability distribution.\"\"\"\n",
    "    return entropy(probabilities, base=2)\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # Open the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert the image to RGB (OpenCV loads images in BGR by default)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to PIL format and apply transformations\n",
    "    image = Image.fromarray(image)\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)  # Move image tensor to the same device as the model\n",
    "\n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # Model output probabilities\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "    # Calculate entropy of the current prediction\n",
    "    entropy_value = calculate_entropy(probabilities)\n",
    "\n",
    "    # Check entropy and decide the predicted class\n",
    "    if entropy_value > ENTROPY_THRESHOLD:\n",
    "        print(f\"High entropy ({entropy_value:.4f}). Defaulting to 'General Medicine'.\")\n",
    "        predicted_class = \"General Medicine\"\n",
    "    else:\n",
    "        # Get the predicted class with the highest probability\n",
    "        predicted_idx = np.argmax(probabilities)\n",
    "        predicted_class = data.classes[predicted_idx]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class} (Entropy: {entropy_value:.4f})\")\n",
    "\n",
    "# Test the model with a random image\n",
    "image_path='/mloscratch/homes/tagemoua/MultiMeditron/image.png'\n",
    "predict_image(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for multiple data length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data folders for multiple numbers of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from PIL import Image, UnidentifiedImageError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 200 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_200/General\n",
      "Copied 200 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General Medecine to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_200/General Medecine\n",
      "Copied 200 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_200/Mri\n",
      "Copied 200 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_200/Ultrasound\n",
      "Copied 200 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_200/Chest_X-ray\n",
      "Copied 500 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500/General\n",
      "Copied 500 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General Medecine to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500/General Medecine\n",
      "Copied 500 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500/Mri\n",
      "Copied 500 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500/Ultrasound\n",
      "Copied 251 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500/Chest_X-ray\n",
      "Copied 1000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_1000/General\n",
      "Copied 1000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General Medecine to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_1000/General Medecine\n",
      "Copied 1000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_1000/Mri\n",
      "Copied 1000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_1000/Ultrasound\n",
      "Copied 251 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_1000/Chest_X-ray\n",
      "Copied 3000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_3000/General\n",
      "Copied 3000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/General Medecine to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_3000/General Medecine\n",
      "Copied 3000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_3000/Mri\n",
      "Copied 3000 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_3000/Ultrasound\n",
      "Copied 251 files from /mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray to /mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_3000/Chest_X-ray\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Number of data points\n",
    "num_data_points = [200, 500, 1000, 3000]\n",
    "\n",
    "input_dirs = [\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/General',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/General Medecine',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray',\n",
    "]\n",
    "for n in num_data_points:\n",
    "    output_dir = f'/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_{n}'\n",
    "    create_subset(input_dirs, output_dir, subset_size=n)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models and compare the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/runai-home/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 349MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3789, Accuracy: 87.32%\n",
      "Validation Loss: 108.3030, Accuracy: 55.00%\n",
      "Epoch [2/10], Loss: 0.1732, Accuracy: 94.52%\n",
      "Validation Loss: 1.0523, Accuracy: 73.12%\n",
      "Epoch [3/10], Loss: 0.0590, Accuracy: 97.81%\n",
      "Validation Loss: 0.6282, Accuracy: 85.00%\n",
      "Epoch [4/10], Loss: 0.1038, Accuracy: 97.18%\n",
      "Validation Loss: 1.7421, Accuracy: 83.12%\n",
      "Stopping early at epoch 4 due to no improvement in accuracy and an increase in loss.\n",
      "[85.0]\n",
      "/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500\n",
      "Epoch [1/10], Loss: 0.3251, Accuracy: 91.00%\n",
      "Validation Loss: 0.3361, Accuracy: 88.29%\n",
      "Epoch [2/10], Loss: 0.0924, Accuracy: 97.00%\n",
      "Validation Loss: 0.0214, Accuracy: 99.14%\n",
      "Epoch [3/10], Loss: 0.0795, Accuracy: 97.64%\n",
      "Validation Loss: 3.0120, Accuracy: 76.00%\n",
      "Stopping early at epoch 3 due to no improvement in accuracy and an increase in loss.\n",
      "[85.0, 99.14285714285714]\n",
      "/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500\n",
      "Epoch [1/10], Loss: 0.1824, Accuracy: 93.88%\n",
      "Validation Loss: 0.1019, Accuracy: 96.92%\n",
      "Epoch [2/10], Loss: 0.0950, Accuracy: 96.73%\n",
      "Validation Loss: 0.1858, Accuracy: 95.69%\n",
      "Stopping early at epoch 2 due to no improvement in accuracy and an increase in loss.\n",
      "[85.0, 99.14285714285714, 96.92307692307692]\n",
      "/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_500\n",
      "Epoch [1/10], Loss: 0.1303, Accuracy: 96.11%\n",
      "Validation Loss: 0.0822, Accuracy: 97.95%\n",
      "Epoch [2/10], Loss: 0.0608, Accuracy: 98.01%\n",
      "Validation Loss: 0.7233, Accuracy: 77.51%\n",
      "Stopping early at epoch 2 due to no improvement in accuracy and an increase in loss.\n",
      "[85.0, 99.14285714285714, 96.92307692307692, 97.94594594594595]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of data points\n",
    "num_data_points = [200, 500, 1000, 3000]\n",
    "\n",
    "input_dirs = [\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/General',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Mri',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Ultrasound',\n",
    "    '/mloscratch/homes/tagemoua/MultiMeditron/processed_data/Chest_X-ray',\n",
    "]\n",
    "\n",
    "best_accuracy_array = []\n",
    "\n",
    "for n in num_data_points:\n",
    "    output_dir = f'/mloscratch/homes/tagemoua/MultiMeditron/processed_data_subset_{n}'\n",
    "\n",
    "    # Dataset preparation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    print(new_data)\n",
    "\n",
    "    data = datasets.ImageFolder(root=output_dir, transform=transform)\n",
    "    # Split the dataset into training and validation sets\n",
    "    train_size = int(0.8 * len(data))\n",
    "    val_size = len(data) - train_size\n",
    "    train_data, val_data = torch.utils.data.random_split(data, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Model preparation\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_classes = len(data.classes)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model with early stopping based on loss and accuracy\n",
    "    num_epochs = 10\n",
    "    best_accuracy = 0.0\n",
    "    prev_loss = float('inf')  # Initialize with a high value\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy for this batch\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Compute epoch loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        if epoch > 0 and val_loss > prev_loss and val_accuracy <= best_accuracy:\n",
    "            print(f\"Stopping early at epoch {epoch+1} due to no improvement in accuracy and an increase in loss.\")\n",
    "            break\n",
    "\n",
    "        best_accuracy = max(best_accuracy, val_accuracy)\n",
    "        prev_loss = val_loss\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), f'modality_classifier_{n}.pth')\n",
    "\n",
    "\n",
    "    best_accuracy_array.append(best_accuracy)\n",
    "    print(best_accuracy_array)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
